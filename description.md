Overview
The mitral valve (MV) is the largest valve of the heart and regulates the blood flow between the left atrium and the left ventricle. It is composed by two leaflets, the anterior and the posterior leaflet, that are attached to a fibrous ring known as the mitral annulus. In healthy patients, the left atrium contracts during diastole and the blood flows through the open MV into the left ventricle while it is dilating.

Echocardiography is a medical imaging technique that produces 2D pictures and videos of the heart using ultrasound waves generated by a transducer, scattered and reflected by biological tissues and read by a detector. Echocardiography is the standard imaging tool in the clinical routine to perform the diagnosis of most of heart diseases and dysfunctions, including MV diseases.

MV segmentation specifies a crucial first step to establish a machine learning pipeline that can support practitioners in performing multiple tasks including the diagnosis of MV diseases, surgical planning, and intra-operative procedures. Therefore, this task will be concerned with the segmentation of the MV in echocardiography videos.

The training set consists of 65 videos in which the MV is labeled in three different frames in each video. Additionally, a bounding box surrounding the MV is provided for each video. The test set consists of 20 videos. For each video in the test set the MV should be segmented for all frames.

Start

a day ago
Close
22 days to go
Description
The samples originate from two different data sets: One data set was labeled by experienced cardiologists and consists of high resolution videos, and the other was labeled by amateurs and has relatively low resolution. While the training data consists of videos from both data sets the test videos (where you need to make the predictions) are evaluated based on expert labels only. It is up to you to decide to which extent you want to use the amateur labeled videos for the training of your model.

The data for this task consists of the following files:

train.pkl - the training data with the videos, bounding boxes, labels and information about the data source. test.pkl - the test data with the videos where the MV should be segmented. task3.ipynb - a helper notebook containing functions for reading and saving the .csv files.

The training data (train.pkl) is a list of dictionaries containing the following keys: name, video, box, label, frames, dataset. A single dictionary has the following structure:

{ 'name': 'AC8ASN45B9', 'video': array([...], dtype='uint8'), 'box': array([...], dtype='bool'), 'label': array([...], dtype='bool'), 'frames': [41, 65, 167], 'dataset': 'amateur' }

The shape of the video is (height, width, number of frames), the box has shape (height, width) and the label has the same shape as the video. The frames is a list of indices (starting at zero), indicating which frames are labeled. The dataset key describes if the video was labeled by amateurs or experts.

The test set file (test.csv) has the same structure but with the labels removed, and with an index in the 'name' (see submission format below).

{ 'name': 'CX86SA56S9_i', 'video': array([...], dtype='uint8') }

Submission format
Your task is to segment the videos. The segmentation mask for each video is a boolean tensor that must have the same shape as the video. A value of 1 in the mask indicates that the corresponding entry in the video is part of the mitral valve.

For your convenience, we further provide a sample submission file (sample.csv). It provides the structure you need to follow in order to create a valid submission file. The predictions must be stored as rows in a csv file with two columns: id and value.

A value in id has the form name_i, where name is the name of a video and i is a unique natural number that acts as an identifier. The number i does not have a meaning and you can choose for it any number you want as long as no two rows have the same value in id. This is required because Kaggle mandates that the id column contains unique entries.

A value in the value column must have the format "[flattenedIdx, len]", where flattenedIdx is the index of the starting point in the flattened mask, and len is a positive integer indicating the number of consecutive ones in the flattened mask. This means that for the flattened mask f, the range f[flattenedIdx:flattenedIdx + len] contains all ones. You can obtain the flattened version of a mask m by calling the method m.flatten() in numpy.

The overall idea is that the prediction is a boolean type mask, where entries marked as "True" describe the pixels corresponding to the mitral valve, and entries marked as "False" describe the background.

The helper notebook (task3.ipynb) provides functions to help you create a valid submission file.

Please keep in mind that, as a group, you have a limited number of submissions, as stated on the submissions page.

Important
You are not allowed to manually segment the mitral valves (neither for training nor during test time)! Dishonest conduct will have the failure of the course as consequence and will be reported.

Make sure that you properly hand in the task, otherwise you may obtain zero points for this task.

Evaluation
The evaluation metric for this task is the median Jaccard Index (IoU) calculated over all test videos.

Mathematically, the formula for the IoU is:


where A is the set describing the ground truth segmentation pixels and B is the set of predicted pixels.

Baseline
The baseline to achieve at least a 4.0 will be a public score of 0.40.

FAQs
Frequently asked questions
Which programming language am I supposed to use? What tools am I allowed to use?
You are free to choose any programming language and use any software library.

Can you help me solve the task? Can you give me a hint?
As the tasks are a graded part of the class, we cannot help you solve them. However, we will try to address general aspects during the project tutorials. Moreover, feel free to ask general questions about the course material during or after the exercise sessions.

Can you give me a deadline extension?
We can not grant deadline extensions, except in extraordinary cases (e.g. military service). However, we will require official confirmation of your problem (e.g. certificate of illness).

Can I post on Moodle as soon as I have a question?
This is highly discouraged. Instead,

Read the details of the task thoroughly.
Review the frequently asked questions.
If there is another team that solved the task, try again.
Discuss with your team mates.
If you still consider that you should contact the TAs, you can post a private question on Moodle. Remember that collaboration with other teams (beyond general discussions) is prohibited.

Am I allowed to use ideas from published papers and use their code?
You are allowed to search for any material that presents how to train models for related tasks (e.g. articles in conferences, repositories, etcâ€¦). However, you must re-implement the code by yourself. You are NOT allowed to copy code.

When will I receive the private scores? And the project grades?
We will publish the private scores before the exam the latest.

Dataset Description
The data for this task consists of the following files:

train.pkl - the training data with the videos, bounding boxes, labels and information about the data source. test.pkl - the test data with the videos where the MV should be segmented. sample.csv - a sample submission file in the correct format. task3.ipynb - a helper notebook containing functions for reading and saving the pickle (*.pkl) files.

The training data (train.pkl) is a list of dictionaries containing the following keys: name, video, box, label, frames, dataset. A single dictionary has the following structure:

{ 'name': 'AC8ASN45B9', 'video': array([...], dtype='uint8'), 'box': array([...], dtype='bool'), 'label': array([...], dtype='bool'), 'frames': [41, 65, 167], 'dataset': 'amateur' }

The shape of the video is (height, width, number of frames), the box has shape (height, width) and the label has the same shape as the video. The frames is a list of indices (starting at zero), indicating which frames are labeled. The dataset key describes if the video was labeled by amateurs or experts.

The test set file (test.pkl) has the same structure but with the labels removed:

{ 'name': 'CX86SA56S9', 'video': array([...], dtype='uint8') }

